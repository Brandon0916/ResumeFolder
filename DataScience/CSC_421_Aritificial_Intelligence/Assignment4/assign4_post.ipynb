{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c8mTdncAL7Qt"
   },
   "source": [
    "Assignment 4 - Classifying handwritten digits using Numpy and Keras.\n",
    "--\n",
    "For this assignment, you should complete the exercises in this notebook. It is similar to the notebook posted for binary logistic regression. \n",
    "\n",
    "Look for requests containing the text **\"your code\"**. E.g. \"put your code here\", \"replace None by your code\", etc.\n",
    "If there is no such request in a cell, just run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2160,
     "status": "ok",
     "timestamp": 1572980556456,
     "user": {
      "displayName": "Alex Thomo",
      "photoUrl": "",
      "userId": "08504196803322236588"
     },
     "user_tz": 480
    },
    "id": "6ey4DpiVL7Q1",
    "outputId": "d29a7184-468b-4380-e299-82a045fdb46a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 589
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3751,
     "status": "ok",
     "timestamp": 1572980558070,
     "user": {
      "displayName": "Alex Thomo",
      "photoUrl": "",
      "userId": "08504196803322236588"
     },
     "user_tz": 480
    },
    "id": "vNZ9U1a3L7RC",
    "outputId": "432bc3b9-bf28-45ef-db0c-6872d17d1c23"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-44264281838f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Let's load the dataset of handwritten digits.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfashion_mnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "# Let's load the dataset of handwritten digits. \n",
    "\n",
    "(X, Y), (X_test, Y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[Y[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3706,
     "status": "ok",
     "timestamp": 1572980558072,
     "user": {
      "displayName": "Alex Thomo",
      "photoUrl": "",
      "userId": "08504196803322236588"
     },
     "user_tz": 480
    },
    "id": "EQGFn7_RL7RR",
    "outputId": "e860c8a9-da1a-49a1-c7f1-ddf97b3d59ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape (60000, 784) (60000, 1)\n",
      "Test dataset shape (10000, 784) (10000, 1)\n",
      "Y = [[9]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [3]\n",
      " [0]\n",
      " [5]]\n"
     ]
    }
   ],
   "source": [
    "# We will reshape (flatten) X arrays so that they become rank 2 arrays. \n",
    "# We will reshape the Y arrays so that they are not rank 1 arrays but rank 2 arrays. \n",
    "# They should be rank 2 arrays.\n",
    "\n",
    "X = X.reshape(X.shape[0], X.shape[1]*X.shape[2])\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2])\n",
    "\n",
    "Y = Y.reshape((Y.shape[0],1))\n",
    "Y_test = Y_test.reshape((Y_test.shape[0],1))\n",
    "\n",
    "print(\"Train dataset shape\", X.shape, Y.shape)\n",
    "print(\"Test dataset shape\", X_test.shape, Y_test.shape)\n",
    "\n",
    "print(\"Y =\", Y)\n",
    "\n",
    "m   = X.shape[0] \n",
    "n_x = X.shape[1]\n",
    "\n",
    "C = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hN_SYXCyL7Rb"
   },
   "source": [
    "Exercise 1 - One Hot Encoding\n",
    "--\n",
    "\n",
    "Convert Y to \"one-hot\" encoding. E.g. if the original Y is \n",
    "$$\n",
    "Y = \\begin{bmatrix}\n",
    "    1 \\\\\n",
    "    5 \\\\\n",
    "    9  \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "the new Y should be\n",
    "$$\n",
    "Y = \\begin{bmatrix}\n",
    "    0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
    "    0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0\\\\\n",
    "    0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\\\\ \n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3674,
     "status": "ok",
     "timestamp": 1572980558073,
     "user": {
      "displayName": "Alex Thomo",
      "photoUrl": "",
      "userId": "08504196803322236588"
     },
     "user_tz": 480
    },
    "id": "q0pbD71OL7Re",
    "outputId": "bfa419b3-9b09-4b15-e998-f20ac5ef1a14"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8f0333a8f638>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Toward this goal, let's check what np.arange(C) produces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Toward this goal, let's check what np.arange(C) produces\n",
    "np.arange(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 133
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3655,
     "status": "ok",
     "timestamp": 1572980558074,
     "user": {
      "displayName": "Alex Thomo",
      "photoUrl": "",
      "userId": "08504196803322236588"
     },
     "user_tz": 480
    },
    "id": "aMM2AxEYL7Rn",
    "outputId": "3fdc72b3-d058-4a5d-e2c5-74ba8db3a5f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [3],\n",
       "       [0],\n",
       "       [5]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see again what Y is\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3638,
     "status": "ok",
     "timestamp": 1572980558074,
     "user": {
      "displayName": "Alex Thomo",
      "photoUrl": "",
      "userId": "08504196803322236588"
     },
     "user_tz": 480
    },
    "id": "IvzFXVaML7Ru",
    "outputId": "8d1b6793-2e00-4b00-f554-6686d507ec39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "broadcasted np.arange(C) = \n",
      " [[0 1 2 ... 7 8 9]\n",
      " [0 1 2 ... 7 8 9]\n",
      " [0 1 2 ... 7 8 9]\n",
      " ...\n",
      " [0 1 2 ... 7 8 9]\n",
      " [0 1 2 ... 7 8 9]\n",
      " [0 1 2 ... 7 8 9]]\n",
      "broadcasted Y = \n",
      " [[9 9 9 ... 9 9 9]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [3 3 3 ... 3 3 3]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [5 5 5 ... 5 5 5]]\n"
     ]
    }
   ],
   "source": [
    "# What would broadcasting these arrays together would look like? \n",
    "# Let's check.\n",
    "\n",
    "a,b = np.broadcast_arrays(np.arange(C), Y)\n",
    "\n",
    "print(\"broadcasted np.arange(C) = \\n\", a)\n",
    "print(\"broadcasted Y = \\n\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3627,
     "status": "ok",
     "timestamp": 1572980558075,
     "user": {
      "displayName": "Alex Thomo",
      "photoUrl": "",
      "userId": "08504196803322236588"
     },
     "user_tz": 480
    },
    "id": "YRLT177UL7R2",
    "outputId": "50cec1f0-61c5-4af4-9366-8bc250b32830"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b2f245e31a9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Put your code in place of None objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mY_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Y_new=\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mY_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# If we compare np.arange(C) with Y using the equality sign ==, \n",
    "# the numpy broadcasting will do its magic to give us what we want. \n",
    "# Try it out. Then assign the result to a new variable Y_new. \n",
    "# Don't worry for the \"True\" and \"False\" values looking like strings. \n",
    "# They behave in fact like numbers, i.e. True is 1, False is 0.\n",
    "# Finally, assign Y_new to Y so that we have to deal with Y in rest of the notebook.\n",
    "# Cast the boolean values of Y_new to integer by calling Y_new.astype(int)\n",
    "\n",
    "# Put your code in place of None objects \n",
    "\n",
    "Y_new = np.arange(C) == Y\n",
    "print(\"Y_new=\", Y_new)\n",
    "Y =Y_new.astype(int)\n",
    "print(\"Y=\",Y)\n",
    "\n",
    "Y_new_test =  np.arange(C) == Y_test\n",
    "print(\"Y_new_test=\", Y_new_test)\n",
    "Y_test = Y_new_test.astype(int)\n",
    "print(\"Y_test=\",Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MW-UxFCiL7R_"
   },
   "source": [
    "*Expected output*\n",
    "\n",
    "<pre>\n",
    "Y_new= [[False False False ... False False  True]\n",
    " [ True False False ... False False False]\n",
    " [ True False False ... False False False]\n",
    " ...\n",
    " [False False False ... False False False]\n",
    " [ True False False ... False False False]\n",
    " [False False False ... False False False]]\n",
    "Y= [[0 0 0 ... 0 0 1]\n",
    " [1 0 0 ... 0 0 0]\n",
    " [1 0 0 ... 0 0 0]\n",
    " ...\n",
    " [0 0 0 ... 0 0 0]\n",
    " [1 0 0 ... 0 0 0]\n",
    " [0 0 0 ... 0 0 0]]\n",
    "Y_new_test= [[False False False ... False False  True]\n",
    " [False False  True ... False False False]\n",
    " [False  True False ... False False False]\n",
    " ...\n",
    " [False False False ... False  True False]\n",
    " [False  True False ... False False False]\n",
    " [False False False ... False False False]]\n",
    "Y_test= [[0 0 0 ... 0 0 1]\n",
    " [0 0 1 ... 0 0 0]\n",
    " [0 1 0 ... 0 0 0]\n",
    " ...\n",
    " [0 0 0 ... 0 1 0]\n",
    " [0 1 0 ... 0 0 0]\n",
    " [0 0 0 ... 0 0 0]]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N2C-B0cCL7SB"
   },
   "source": [
    "Exercise 2 - The Softmax Function\n",
    "--\n",
    "(Adapted from Andrew Ng's exercise in Coursera, deeplearning.ai)\n",
    "\n",
    "Implement a softmax function using numpy. Softmax is a normalizing function used when the algorithm needs to classify two or more classes. \n",
    "\n",
    "**Instructions**:\n",
    "- for $x \\in \\mathbb{R}^{1\\times n}$ \n",
    "$$\\mbox{softmax}(x) = \\mbox{softmax}\\left(\\begin{bmatrix}\n",
    "    x_1  &&\n",
    "    x_2 &&\n",
    "    ...  &&\n",
    "    x_n  \n",
    "\\end{bmatrix}\\right) = \\begin{bmatrix}\n",
    "     \\frac{e^{x_1}}{\\sum_{j}e^{x_j}}  &&\n",
    "    \\frac{e^{x_2}}{\\sum_{j}e^{x_j}}  &&\n",
    "    ...  &&\n",
    "    \\frac{e^{x_n}}{\\sum_{j}e^{x_j}} \n",
    "\\end{bmatrix} $$ \n",
    "\n",
    "- for a matrix $x \\in \\mathbb{R}^{m \\times n}$  \n",
    "$$\\mbox{softmax}(x) = \\mbox{softmax}\\begin{bmatrix}\n",
    "    x_{11} & x_{12} & x_{13} & \\dots  & x_{1n} \\\\\n",
    "    x_{21} & x_{22} & x_{23} & \\dots  & x_{2n} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    x_{m1} & x_{m2} & x_{m3} & \\dots  & x_{mn}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "    \\frac{e^{x_{11}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{12}}}{\\sum_{j}e^{x_{1j}}} & \\frac{e^{x_{13}}}{\\sum_{j}e^{x_{1j}}} & \\dots  & \\frac{e^{x_{1n}}}{\\sum_{j}e^{x_{1j}}} \\\\\n",
    "    \\frac{e^{x_{21}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{22}}}{\\sum_{j}e^{x_{2j}}} & \\frac{e^{x_{23}}}{\\sum_{j}e^{x_{2j}}} & \\dots  & \\frac{e^{x_{2n}}}{\\sum_{j}e^{x_{2j}}} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\frac{e^{x_{m1}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m2}}}{\\sum_{j}e^{x_{mj}}} & \\frac{e^{x_{m3}}}{\\sum_{j}e^{x_{mj}}} & \\dots  & \\frac{e^{x_{mn}}}{\\sum_{j}e^{x_{mj}}}\n",
    "\\end{bmatrix} = \\begin{pmatrix}\n",
    "    \\mbox{softmax}\\text{(first row of x)}  \\\\\n",
    "    \\mbox{softmax}\\text{(second row of x)} \\\\\n",
    "    ...  \\\\\n",
    "    \\mbox{softmax}\\text{(last row of x)} \\\\\n",
    "\\end{pmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3613,
     "status": "ok",
     "timestamp": 1572980558075,
     "user": {
      "displayName": "Alex Thomo",
      "photoUrl": "",
      "userId": "08504196803322236588"
     },
     "user_tz": 480
    },
    "id": "hHKcMiLtL7SE",
    "outputId": "faed5ff8-6b02-456b-9388-7390a6cb5d8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax(x) = None\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    # This normalization is done to avoid number overflow. \n",
    "    # See: https://stats.stackexchange.com/questions/304758/softmax-overflow\n",
    "    x_normalized = x - np.max(x,axis=1,keepdims=True)\n",
    "\n",
    "    # Create an array x_exp by applying np.exp() element-wise to x_normalized. \n",
    "    # Put your code here (one line)\n",
    "\n",
    "    # Create an array x_sum that contains the sum of each row of x_exp. \n",
    "    # Use np.sum(..., axis = 1, keepdims = True).\n",
    "    # Put your code here (one line)\n",
    "    \n",
    "    # Compute softmax(x) by dividing x_exp by x_sum. \n",
    "    # It should automatically use numpy broadcasting.\n",
    "    # Return this array.\n",
    "    # Add a very small constant, 1e-15, to each matrix entry (using broadcasting) \n",
    "    # in order to avoid any pure-zero entries.\n",
    "    # This number doesn't make predictions much off, and it solves the log(0) issue\n",
    "    # in the cross-entropy function.\n",
    "    # Replace None with your code\n",
    "    return None\n",
    "\n",
    "\n",
    "# Let's test\n",
    "x = np.array([\n",
    "    [1, 2, 3, 1, 2],\n",
    "    [9, 5, 1, 0 ,0]])\n",
    "print(\"softmax(x) = \" + str(softmax(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RZHr7n8lL7SS"
   },
   "source": [
    "*Expected output*\n",
    "\n",
    "<pre>\n",
    "softmax(x) = [[  6.74508059e-02   1.83350300e-01   4.98397788e-01   6.74508059e-02\n",
    "    1.83350300e-01]\n",
    " [  9.81452586e-01   1.79759312e-02   3.29240664e-04   1.21120871e-04\n",
    "    1.21120871e-04]]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "623TW6qDL7SX"
   },
   "source": [
    "Exercise 3 - Compute one semi-vectorized iteration for softmax\n",
    "--\n",
    "Perform one semi-vectorized iteration of gradient descent for the softmax classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 133
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3598,
     "status": "ok",
     "timestamp": 1572980558076,
     "user": {
      "displayName": "Alex Thomo",
      "photoUrl": "",
      "userId": "08504196803322236588"
     },
     "user_tz": 480
    },
    "id": "5-Zc5Ko6L7Sd",
    "outputId": "e96f89ca-925f-45fc-d208-ac77faa63aef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y None\n",
      "z None\n",
      "a None\n",
      "J None\n",
      "dz None\n",
      "dw None\n",
      "db None\n"
     ]
    }
   ],
   "source": [
    "# First do this for only one training example (the first one, i=0).\n",
    "# Print out everything you compute, e.g. print(\"z\", z), print(\"a\", a), etc. \n",
    "\n",
    "J = 0\n",
    "w = np.zeros((n_x,C))\n",
    "b = np.zeros((1,C))\n",
    "\n",
    "dw = np.zeros((n_x,C));\n",
    "db = np.zeros((1,C));\n",
    "\n",
    "i = 0;\n",
    "\n",
    "\n",
    "# Replace None objects by your code\n",
    "\n",
    "x = X[i:i+1, : ]  #x is [1,784]\n",
    "y = None\n",
    "print(\"y\", y)\n",
    "\n",
    "z = None\n",
    "print(\"z\", z)\n",
    "a = None\n",
    "print(\"a\", a)\n",
    "J = None\n",
    "print(\"J\", J)\n",
    "\n",
    "dz = None\n",
    "print(\"dz\", dz)\n",
    "dw = None\n",
    "print(\"dw\", dw)\n",
    "db = None\n",
    "print(\"db\", db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q8HtgfhsL7So"
   },
   "source": [
    "*Expected output*\n",
    "\n",
    "<pre>\n",
    "y [[0 0 0 0 0 0 0 0 0 1]]\n",
    "z [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
    "a [[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
    "J 2.3025850929940357\n",
    "dz [[ 0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1 -0.9]]\n",
    "dw [[0. 0. 0. ... 0. 0. 0.]\n",
    " [0. 0. 0. ... 0. 0. 0.]\n",
    " [0. 0. 0. ... 0. 0. 0.]\n",
    " ...\n",
    " [0. 0. 0. ... 0. 0. 0.]\n",
    " [0. 0. 0. ... 0. 0. 0.]\n",
    " [0. 0. 0. ... 0. 0. 0.]]\n",
    "db [[ 0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1  0.1 -0.9]]\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3586,
     "status": "ok",
     "timestamp": 1572980558077,
     "user": {
      "displayName": "Alex Thomo",
      "photoUrl": "",
      "userId": "08504196803322236588"
     },
     "user_tz": 480
    },
    "id": "t3ZjsusiL7Sr",
    "outputId": "d11d5019-ba55-4e0e-fa98-6fbed9b8a221"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J 0.0\n",
      "Time needed:  0.004528522491455078\n"
     ]
    }
   ],
   "source": [
    "#one iteration, semi-vectorized\n",
    "\n",
    "J = 0\n",
    "w = np.zeros((n_x,C))\n",
    "b = np.zeros((1,C))\n",
    "\n",
    "dw = np.zeros((n_x,C));\n",
    "db = np.zeros((1,C));\n",
    "\n",
    "alpha = 0.000001\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(m):\n",
    "    # Put your code here\n",
    "    None\n",
    "\n",
    "J /= m; dw /= m; db /= m\n",
    "\n",
    "w -= alpha*dw\n",
    "b -= alpha*db\n",
    "\n",
    "print(\"J\", J)\n",
    "print(\"Time needed: \", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u1Mli1Y5L7S0"
   },
   "source": [
    "*Expected output*\n",
    "\n",
    "<pre>\n",
    "J =  2.302585092995416\n",
    "Time needed:  5.705857038497925\n",
    "</pre>\n",
    "\n",
    "Of course, your running time will be different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fLV-hTE8L7S4"
   },
   "source": [
    "Exercise 4 - Compute one fully-vectorized iteration for softmax\n",
    "--\n",
    "Perform one fully-vectorized iteration of gradient descent for the softmax classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3574,
     "status": "ok",
     "timestamp": 1572980558080,
     "user": {
      "displayName": "Alex Thomo",
      "photoUrl": "",
      "userId": "08504196803322236588"
     },
     "user_tz": 480
    },
    "id": "thiAcUhjL7S8",
    "outputId": "d4c89304-3931-47c6-a4c6-b991486c7fd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J =  None\n",
      "Time needed:  0.0005636215209960938\n"
     ]
    }
   ],
   "source": [
    "#one iteration, fully vectorized, no for loop\n",
    "\n",
    "J = 0\n",
    "w = np.zeros((n_x,C))\n",
    "b = np.zeros((1,C))\n",
    "\n",
    "alpha = 0.000001\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "#Replace the None objects and alpha*0 by your code.\n",
    "\n",
    "# Convention: \n",
    "# Use capital letter when the variable is for the whole dataset of m train examples.\n",
    "\n",
    "# X is (55000,784), Y is (55000,10), w is (784,10), b is (1,10)  \n",
    "Z = None               # Z is  (55000, 10)\n",
    "A = None              # A is  (55000, 10)\n",
    "J = None \n",
    "\n",
    "dZ = None                 # dZ is (55000, 10)\n",
    "\n",
    "\n",
    "dw = None                #dw is (784, 10) \n",
    "db = None\n",
    "\n",
    "w -= alpha*0\n",
    "b -= alpha*0\n",
    "\n",
    "print(\"J = \", J)\n",
    "print(\"Time needed: \", time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W-3eVmQZL7TE"
   },
   "source": [
    "*Expected output*\n",
    "\n",
    "<pre>\n",
    "J =  2.3025850929940366\n",
    "Time needed:  0.6775269508361816\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ktUmO0jcL7TH"
   },
   "source": [
    "We observe that the time of the fully vectorized version is almost one order of magnitude smaller. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zHMu5onlL7TN"
   },
   "source": [
    "Exercise 5 - Compute several fully-vectorized iterations for softmax\n",
    "--\n",
    "Perform 100 fully-vectorized iterations of gradient descent for the softmax classification.\n",
    "Start with doing 10 iterations first, check the accuracy you achieve, then try for 100 iterations. \n",
    "Print out the cost after each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3559,
     "status": "ok",
     "timestamp": 1572980558081,
     "user": {
      "displayName": "Alex Thomo",
      "photoUrl": "",
      "userId": "08504196803322236588"
     },
     "user_tz": 480
    },
    "id": "N49FhkluL7TR",
    "outputId": "fd751d27-1fe2-4940-9b21-2e0b23133b0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 None\n",
      "1 None\n",
      "2 None\n",
      "3 None\n",
      "4 None\n",
      "5 None\n",
      "6 None\n",
      "7 None\n",
      "8 None\n",
      "9 None\n"
     ]
    }
   ],
   "source": [
    "J = 0\n",
    "w = np.zeros((n_x,C))\n",
    "b = np.zeros((1,C))\n",
    "\n",
    "alpha = 0.000001\n",
    "\n",
    "#Replace the None objects and alpha*0 by your code.\n",
    "\n",
    "# Convention: \n",
    "# Use capital letter when the variable is for the whole dataset of m train examples.\n",
    "\n",
    "for iter in range(10):\n",
    "    # X is (55000,784), Y is (55000,10), w is (784,10), b is (1,10)  \n",
    "    Z = None               # Z is  (55000, 10)\n",
    "    A = None              # A is  (55000, 10)\n",
    "    J = None \n",
    "    print(iter, J)\n",
    "    \n",
    "    dZ = None                 # dZ is (55000, 10)\n",
    "\n",
    "\n",
    "    dw = None                #dw is (784, 10) \n",
    "    db = None\n",
    "\n",
    "    w -= alpha*0\n",
    "    b -= alpha*0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FCn6Qp67L7TZ"
   },
   "source": [
    "*Expected output*\n",
    "\n",
    "<pre>\n",
    "0 2.3025850929940366\n",
    "1 2.146205548481119\n",
    "2 2.030819399467471\n",
    "3 1.9311838198434277\n",
    "4 1.8436117384575559\n",
    "5 1.7662245987459277\n",
    "6 1.6975659726233228\n",
    "7 1.636412794191129\n",
    "8 1.581725819043199\n",
    "9 1.5326221800639164\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jF4nNOZCL7Tb"
   },
   "source": [
    "Exercise 6 - Compute the accuracy\n",
    "--\n",
    "Compute the accuracy of softmax classification on the train and test datasets.\n",
    "\n",
    "Use np.argmax(A, 1) and np.argmax(Y, 1) to find the predicted and real class for each example. They return an array of numbers each, e.g. [7 3 9 ..., 8 0 8] and [7 3 4 ..., 5 6 8]. Compare them using ==. You will get an array of booleans, e.g. [ True  True False ..., False False  True]. Sum up the latter using np.sum(). True values will be considered 1, False values will be considered 0, so the sum will tell us how many True values we got. Then divide by Y.shape[0] and multiply by 100 to get the accuracy in percentage.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3740,
     "status": "ok",
     "timestamp": 1572980558276,
     "user": {
      "displayName": "Alex Thomo",
      "photoUrl": "",
      "userId": "08504196803322236588"
     },
     "user_tz": 480
    },
    "id": "nR9Ympa3L7Td",
    "outputId": "26b279ff-cfd9-4129-abb0-fd4ec5c62222"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the train set is  None\n",
      "Accuracy on the test set is  None\n"
     ]
    }
   ],
   "source": [
    "# Replace None by your code\n",
    "\n",
    "def accuracy(A, Y):\n",
    "    return None\n",
    "\n",
    "Z = X @ w + b\n",
    "A = softmax(Z)\n",
    "\n",
    "Z_test = X_test @ w + b\n",
    "A_test = softmax(Z_test)\n",
    "\n",
    "print(\"Accuracy on the train set is \", accuracy(A,Y))\n",
    "print(\"Accuracy on the test set is \", accuracy(A_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "54jGF9mmL7Tm"
   },
   "source": [
    "*Expected output*\n",
    "\n",
    "<pre>\n",
    "Accuracy on the train set is  66.35166666666667\n",
    "Accuracy on the test set is  65.38\n",
    "</pre>\n",
    "\n",
    "Remark. These numbers are for 10 iterations. When you perform 100 iterations, the numbers will be much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ca6YOU5L7To"
   },
   "source": [
    "Exercise 7 - Implement the Softmax classifier using Keras\n",
    "--\n",
    "Implement the Softmax classifier using Keras. This is similar to examples shown in class. Use categorical crossentropy for loss function. Use stochastic optimization (rmsprop or adam) with 5 epochs. Produce the accuracy on the test set in the end. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wIDbrK6kL7Ue"
   },
   "source": [
    "Exercise 8 - Implement a neural network with one hidden layer using Keras.\n",
    "--\n",
    "Turn the previous exercise into a 1-hidden layer neural network with rectified linear units and 15 hidden nodes. The output layer should continue to be softmax.\n",
    "\n",
    "The hidden layer should be fully connected to the input layer and to the output layer.\n",
    "\n",
    "Check the accuracy on the test set. If it is lower than 80%, increase the number of hidden nodes until you reach or exceed this level accuracy."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assign4_post.ipynb",
   "provenance": [
    {
     "file_id": "1jxR0ibfXu7XgrH4Pw5_tmOuFdtEEZWnL",
     "timestamp": 1572726862817
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
